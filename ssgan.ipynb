{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ssgan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJb_eBKEwXS6",
        "colab_type": "text"
      },
      "source": [
        "http://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Self-Supervised_GANs_via_Auxiliary_Rotation_Loss_CVPR_2019_paper.pdf\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6R34jh5xKkW",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eLP4fR6wCYc",
        "colab_type": "code",
        "outputId": "99e1ca3c-bbcc-4548-c128-a077d6d9335e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "keras.backend.clear_session()\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv8Oaw_gS_pn",
        "colab_type": "text"
      },
      "source": [
        "## WGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMpei4bz6i3d",
        "colab_type": "text"
      },
      "source": [
        "the discriminator is trained to detect rotation angles based only on the true data. In other words, the parameters of the discriminator get updated only based on the rotation loss on the true data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naZ00jyldvMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WGAN(keras.Model):\n",
        "  def __init__(self, discriminator, generator, latent_dim, disc_rot_param = 1.0, gen_rot_param = 0.2):\n",
        "    super(WGAN, self).__init__()\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.latent_dim = latent_dim\n",
        "    self.disc_rot_param = disc_rot_param\n",
        "    self.gen_rot_param = gen_rot_param\n",
        "\n",
        "  def compile(self, d_optimizer, g_optimizer):\n",
        "    super(WGAN, self).compile()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "\n",
        "  def rotate_(self, images, batch_size):\n",
        "    #Apply rotations to the images\n",
        "    images1 = images # rotation = 0\n",
        "    images2 = tf.image.rot90(images, k = 1)#rotation=90\n",
        "    images3 = tf.image.rot90(images, k = 2)#rotation=180\n",
        "    images4 = tf.image.rot90(images, k = 3)#rotation=270\n",
        "\n",
        "    images_all = tf.concat([images1, images2, images3, images4], axis=0)\n",
        "\n",
        "    images_all_label = tf.repeat(np.arange(4, dtype=np.int32), batch_size)\n",
        "\n",
        "    return images_all, images_all_label\n",
        "\n",
        "  def rot_acc(self, logits, y):\n",
        "    preds = keras.activations.softmax(logits, axis=-1)\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(tf.cast(tf.argmax(preds, 1), tf.int32), y),\n",
        "                                      tf.float32))\n",
        "\n",
        "  def generate(self,z): \n",
        "    return self.generator(z)\n",
        "\n",
        "  def discriminate(self,imgs):\n",
        "    return self.discriminator(imgs)\n",
        "\n",
        "  def train_step(self, real_images):\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "    #Train Critic 1 times\n",
        "    for _ in range(1):\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        random_latent_vectors = tf.random.uniform(shape=(batch_size, self.latent_dim), minval=0.0, maxval=0.99)\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generate(random_latent_vectors)\n",
        "\n",
        "        # Rotated images and labels\n",
        "        rotated_real_imgs, rotated_real_labels= self.rotate_(real_images, batch_size)\n",
        "\n",
        "        # Get the outputs for real and fake images\n",
        "        disc_real, _ = self.discriminate(real_images)\n",
        "        disc_fake, _ = self.discriminate(generated_images)\n",
        "\n",
        "        # Get the rotation outputs for real and fake images \n",
        "        _, disc_rot = self.discriminate(rotated_real_imgs)\n",
        "\n",
        "        # Get the loss going\n",
        "        disc_rot_acc = self.rot_acc(disc_rot, rotated_real_labels)\n",
        "\n",
        "        disc_rot_loss =  tf.reduce_mean(tf.keras.losses.categorical_crossentropy( #Rotation loss for the discriminator\n",
        "                                    tf.one_hot(rotated_real_labels, 4),\n",
        "                                    disc_rot, from_logits=True))\n",
        "        \n",
        "        disc_loss = - tf.reduce_mean(disc_real) + tf.reduce_mean(disc_fake)\n",
        "        disc_loss += self.disc_rot_param * disc_rot_loss\n",
        "\n",
        "      # Train the discriminator\n",
        "      d_grads = disc_tape.gradient(disc_loss, self.discriminator.trainable_weights)\n",
        "      self.d_optimizer.apply_gradients(zip(d_grads, self.discriminator.trainable_weights))\n",
        "\n",
        "    # Train the generator 1 time\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      random_latent_vectors = tf.random.uniform(shape=(batch_size, self.latent_dim), minval=0.0, maxval=0.99)\n",
        "\n",
        "      # Decode them to fake images\n",
        "      generated_images = self.generate(random_latent_vectors)\n",
        "\n",
        "      # Rotated images and labels\n",
        "      rotated_fakes_imgs, rotated_fakes_labels= self.rotate_(generated_images, batch_size)\n",
        "\n",
        "      # Get the rotation outputs for real and fake images \n",
        "      _, gen_rot = self.discriminate(rotated_fakes_imgs)\n",
        "      \n",
        "      # Get the outputs for fake images\n",
        "      disc_fake, _ = self.discriminate(generated_images)        \n",
        "\n",
        "      # Get the loss going\n",
        "      gen_rot_acc = self.rot_acc(gen_rot, rotated_fakes_labels)\n",
        "\n",
        "      gen_rot_loss =  tf.reduce_mean(keras.losses.categorical_crossentropy( #Rotation loss for the generator\n",
        "                                     tf.one_hot(rotated_fakes_labels, 4),\n",
        "                                     gen_rot, from_logits=True))\n",
        "      gen_loss = - tf.reduce_mean(disc_fake) + self.gen_rot_param * gen_rot_loss\n",
        "\n",
        "    g_grads = gen_tape.gradient(gen_loss, self.generator.trainable_weights)\n",
        "    self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_weights))\n",
        "\n",
        "    return {'d_loss': disc_loss, 'g_loss': gen_loss, 'd_rot_acc': disc_rot_acc, 'g_rot_acc': gen_rot_acc}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd9rxegeStk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUF=60000\n",
        "BATCH_SIZE=32\n",
        "TEST_BUF=10000\n",
        "DIMS = (28,28,1)\n",
        "latent_dim = 64\n",
        "N_TRAIN_BATCHES =int(TRAIN_BUF/BATCH_SIZE)\n",
        "N_TEST_BATCHES = int(TEST_BUF/BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8HCBbqc0XkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spectral norm from https://colab.research.google.com/drive/1f2Ejlm3UmsthqQni9vFkGmTTcS_ndqXR#scrollTo=vQ0QgmWmOE64\n",
        "\n",
        "from tensorflow.keras.constraints import Constraint\n",
        "\n",
        "def l2_normalize(x, eps=1e-12):\n",
        "  '''\n",
        "  Scale input by the inverse of it's euclidean norm\n",
        "  '''\n",
        "  return x / tf.linalg.norm(x + eps)\n",
        "\n",
        "class Spectral_Norm(Constraint):\n",
        "    '''\n",
        "    Uses power iteration method to calculate a fast approximation \n",
        "    of the spectral norm (Golub & Van der Vorst)\n",
        "    The weights are then scaled by the inverse of the spectral norm\n",
        "    '''\n",
        "    def __init__(self, power_iters=POWER_ITERATIONS):\n",
        "        self.n_iters = power_iters\n",
        "\n",
        "    def __call__(self, w):\n",
        "      flattened_w = tf.reshape(w, [w.shape[0], -1])\n",
        "      u = tf.random.normal([flattened_w.shape[0]])\n",
        "      v = tf.random.normal([flattened_w.shape[1]])\n",
        "      for i in range(self.n_iters):\n",
        "        v = tf.linalg.matvec(tf.transpose(flattened_w), u)\n",
        "        v = l2_normalize(v)\n",
        "        u = tf.linalg.matvec(flattened_w, v)\n",
        "        u = l2_normalize(u)\n",
        "      sigma = tf.tensordot(u, tf.linalg.matvec(flattened_w, v), axes=1)\n",
        "      return w / sigma\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'n_iters': self.n_iters}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpLlvmD-gAji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the discriminator\n",
        "def discriminator_model():\n",
        "  inp = keras.Input(shape=DIMS, name = \"disc_input\")\n",
        "  netw = layers.Conv2D(32, (3, 3), strides=(1, 1), kernel_constraint=Spectral_Norm(),\n",
        "                padding='same')(inp)\n",
        "  netw = layers.LeakyReLU(alpha=0.2)(netw)\n",
        "  netw = layers.Conv2D(64, (4, 4), strides=(2, 2), kernel_constraint=Spectral_Norm(),\n",
        "                padding='same')(netw)\n",
        "  netw = layers.LeakyReLU(alpha=0.2)(netw)\n",
        "  netw = layers.Conv2D(128, (3, 3), strides=(1, 1), kernel_constraint=Spectral_Norm(),\n",
        "                padding='same')(netw)\n",
        "  netw = layers.LeakyReLU(alpha=0.2)(netw)\n",
        "\n",
        "  net_disc = layers.GlobalMaxPooling2D()(netw)\n",
        "  net_disc = layers.Dense(units=1, kernel_constraint=Spectral_Norm())(net_disc)\n",
        "\n",
        "  net_ss = layers.Flatten()(netw)\n",
        "  net_ss = layers.Dense(units=4, kernel_constraint=Spectral_Norm())(net_ss)\n",
        "\n",
        "  model = tf.keras.Model(inputs=inp, outputs=[net_disc,net_ss])\n",
        "  return model\n",
        "\n",
        "w_critic = discriminator_model()\n",
        "\n",
        "# Create the generator\n",
        "def generator_model():\n",
        "  inp = keras.Input(shape=(latent_dim,), name=\"gen_input\")\n",
        "  # We want to generate 64 coefficients to reshape into a 64 map\n",
        "  netw = layers.Dense(7 * 7 * latent_dim)(inp)\n",
        "  netw = layers.ReLU()(netw)\n",
        "  netw = layers.Reshape((7, 7, latent_dim))(netw)\n",
        "  netw = layers.Conv2DTranspose(latent_dim * 2, (3, 3), strides=(2, 2), padding='same')(netw)\n",
        "  netw = layers.ReLU()(netw)\n",
        "  netw = layers.Conv2DTranspose(latent_dim * 4, (3, 3), strides=(2, 2), padding='same')(netw)\n",
        "  netw = layers.ReLU()(netw)\n",
        "  netw = layers.Conv2DTranspose(latent_dim * 8, (4, 4), strides=(2, 2), padding='same')(netw)\n",
        "  netw = layers.ReLU()(netw)\n",
        "  netw = layers.Conv2D(1, (3, 3), strides=(2, 2), padding='same', activation='sigmoid')(netw)\n",
        "  model = tf.keras.Model(inputs=inp, outputs=netw)\n",
        "  return model\n",
        "\n",
        "generator = generator_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flzcU1JTSxlE",
        "colab_type": "code",
        "outputId": "db600945-3a22-45db-ae9e-a5a300cb6c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# load dataset\n",
        "(train_images, _), (test_images, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# split dataset\n",
        "train_images = np.reshape(train_images,(-1, 28, 28, 1)).astype(\n",
        "    \"float32\"\n",
        ") / 255.0\n",
        "test_images = np.reshape(test_images,(-1, 28, 28, 1)).astype(\"float32\") / 255.0\n",
        "\n",
        "# batch datasets\n",
        "train_dataset = (\n",
        "    tf.data.Dataset.from_tensor_slices(train_images)\n",
        "    .shuffle(TRAIN_BUF)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "test_dataset = (\n",
        "    tf.data.Dataset.from_tensor_slices(test_images)\n",
        "    .shuffle(TEST_BUF)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wd1_XUjTE_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_optimizer = keras.optimizers.Adam(0.0002, beta_1=0.5)\n",
        "disc_optimizer = keras.optimizers.Adam(0.0001)\n",
        "# model\n",
        "model = WGAN(\n",
        "    generator = generator,\n",
        "    discriminator = w_critic,\n",
        "    latent_dim = latent_dim,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    d_optimizer=disc_optimizer,\n",
        "    g_optimizer=gen_optimizer,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNn9M0nIT4lv",
        "colab_type": "code",
        "outputId": "0ed624d2-44c0-4b60-d31a-589abe98c688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        }
      },
      "source": [
        "hist = model.fit(train_dataset, epochs=20)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 862s 460ms/step - d_loss: 0.5778 - g_loss: -0.2299 - d_rot_acc: 0.8037 - g_rot_acc: 0.9704\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 858s 458ms/step - d_loss: 0.4499 - g_loss: -0.0390 - d_rot_acc: 0.8501 - g_rot_acc: 0.9721\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 864s 461ms/step - d_loss: 0.2984 - g_loss: 0.3902 - d_rot_acc: 0.8496 - g_rot_acc: 0.9833\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 861s 459ms/step - d_loss: -1.3378 - g_loss: 1.2421 - d_rot_acc: 0.8390 - g_rot_acc: 0.9800\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 860s 459ms/step - d_loss: -4.8154 - g_loss: 1.4053 - d_rot_acc: 0.8289 - g_rot_acc: 0.7175\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 856s 457ms/step - d_loss: -22.2828 - g_loss: -3.0212 - d_rot_acc: 0.8560 - g_rot_acc: 0.2500\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 861s 459ms/step - d_loss: -4.5067 - g_loss: 18.1564 - d_rot_acc: 0.8569 - g_rot_acc: 0.9932\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 848s 452ms/step - d_loss: -8.2298 - g_loss: 12.6121 - d_rot_acc: 0.8579 - g_rot_acc: 0.6210\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 840s 448ms/step - d_loss: -20.8157 - g_loss: -0.6284 - d_rot_acc: 0.8614 - g_rot_acc: 0.2500\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 845s 451ms/step - d_loss: -18.7391 - g_loss: 0.9010 - d_rot_acc: 0.8673 - g_rot_acc: 0.2500\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 848s 452ms/step - d_loss: -15.7503 - g_loss: 1.3867 - d_rot_acc: 0.8619 - g_rot_acc: 0.2500\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 849s 453ms/step - d_loss: -19.5271 - g_loss: 0.5968 - d_rot_acc: 0.8610 - g_rot_acc: 0.2500\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 848s 452ms/step - d_loss: -19.0367 - g_loss: 1.0582 - d_rot_acc: 0.8657 - g_rot_acc: 0.2500\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 848s 452ms/step - d_loss: -18.8574 - g_loss: 1.3749 - d_rot_acc: 0.8663 - g_rot_acc: 0.2500\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 844s 450ms/step - d_loss: -19.1891 - g_loss: 1.4677 - d_rot_acc: 0.8654 - g_rot_acc: 0.2500\n",
            "Epoch 16/20\n",
            " 182/1875 [=>............................] - ETA: 12:36 - d_loss: -19.2069 - g_loss: 1.6374 - d_rot_acc: 0.8662 - g_rot_acc: 0.2500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-bc02c5e2b4f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu2YYKaHUGE2",
        "colab_type": "code",
        "outputId": "df2047a8-339d-44ed-ee23-989535dd343d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# exampled data for plotting results\n",
        "def plot_reconstruction(model, nex=8, zm=2):\n",
        "    samples = model.predict(tf.random.uniform(shape=(BATCH_SIZE, latent_dim), minval=0.0, maxval=0.99))\n",
        "    fig, axs = plt.subplots(ncols=nex, nrows=1, figsize=(zm * nex, zm))\n",
        "    for axi in range(nex):\n",
        "        axs[axi].matshow(\n",
        "                    samples[axi].squeeze(), cmap=plt.cm.Greys, vmin=0, vmax=1\n",
        "                )\n",
        "        axs[axi].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "plot_reconstruction(generator)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAABtCAYAAAAI5vRhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAACkklEQVR4nO3dMQrDMBBFwTjk/lfetIFHSBOQWWZagxH86qFC18w8AAAA4NPz9AEAAAC4H7EIAABAiEUAAABCLAIAABBiEQAAgBCLAAAAxOvHd+9qnHP98V92PMeOO9hxBzvuYMcd7LiDHXf4uqObRQAAAEIsAgAAEGIRAACAEIsAAACEWAQAACDEIgAAACEWAQAACLEIAABAiEUAAABCLAIAABBiEQAAgBCLAAAAhFgEAAAgxCIAAAAhFgEAAAixCAAAQIhFAAAAQiwCAAAQYhEAAIAQiwAAAIRYBAAAIMQiAAAAIRYBAAAIsQgAAECIRQAAAEIsAgAAEGIRAACAEIsAAACEWAQAACDEIgAAACEWAQAACLEIAABAiEUAAABCLAIAABBiEQAAgBCLAAAAhFgEAAAgxCIAAAAhFgEAAAixCAAAQIhFAAAAQiwCAAAQYhEAAIAQiwAAAIRYBAAAIMQiAAAAIRYBAAAIsQgAAECIRQAAAEIsAgAAEGIRAACAEIsAAACEWAQAACDEIgAAACEWAQAACLEIAABAiEUAAABCLAIAABBiEQAAgBCLAAAAhFgEAAAgxCIAAAAhFgEAAAixCAAAQIhFAAAAQiwCAAAQYhEAAIAQiwAAAIRYBAAAIMQiAAAAIRYBAAAIsQgAAECIRQAAAEIsAgAAEGIRAACAEIsAAACEWAQAACDEIgAAACEWAQAACLEIAABAiEUAAABCLAIAABBiEQAAgBCLAAAAhFgEAAAgxCIAAAAhFgEAAAixCAAAQIhFAAAAQiwCAAAQYhEAAIAQiwAAAIRYBAAAIMQiAAAAcc3M6TMAAABwM24WAQAACLEIAABAiEUAAABCLAIAABBiEQAAgBCLAAAAxBshug7VrdUwogAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1152x144 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca-Z3-PNgTG9",
        "colab_type": "code",
        "outputId": "3da9b959-d6e2-4929-a8b3-06e43ebe12ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "# Get training and test loss histories\n",
        "d_loss = hist.history['d_loss']\n",
        "g_loss = hist.history['g_loss']\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(d_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.plot(epoch_count, d_loss, 'r--')\n",
        "plt.plot(epoch_count, g_loss, 'b-')\n",
        "\n",
        "plt.legend(['Critic Loss', 'Generator Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show();"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-07e1dea6e746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'g_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create count of the number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepoch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQdP0LrGaVKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}